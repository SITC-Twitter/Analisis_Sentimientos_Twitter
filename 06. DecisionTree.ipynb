{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/UPM/EscPolitecnica/EscUpmPolit_p.gif \"UPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo final SITC\n",
    "## Análisis de sentimientos en Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Departamento de Ingeniería de Sistemas Telemáticos. Universidad Politécnica de Madrid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizado por:\n",
    "- Juan Bermudo Mera\n",
    "- Margarita Bolívar Jiménez\n",
    "- Lourdes Fernández Nieto\n",
    "- Ramón Pérez Hernández\n",
    "\n",
    "© 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo DecisionTree aplicado sobre el fichero de tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "\n",
    "* [Importación de datos necesarios para aplicar el algoritmo](#1.-Importación-de-datos-necesarios-para-aplicar-el-algoritmo)\n",
    "\t* [Importación de librerías](#Importación-de-librerías)\n",
    "    * [Importación de corpus y tweets](#Importación-de-corpus-y-tweets)\n",
    "    * [Tokenización y stemming](#Tokenización-y-stemming)\n",
    "* [Entrenamiento del modelo](#2.-Entrenamiento-del-modelo)\n",
    "* [Rendimiento del modelo](#3.-Rendimiento-del-modelo)\n",
    "* [Predicción de la polaridad](#4.-Predicción-de-la-polaridad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de datos necesarios para aplicar el algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lourdes/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Lourdes/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerías. Las que no están instaladas, instalar con pip install <nombre_paquete>\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Importación de corpus y tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se importan el corpus y los tweets\n",
    "tweets_df = pd.read_excel('ficheros/Preprocesados/tweets_corpus_header.xlsx', header=0, encoding='iso8859_15')\n",
    "tweets = pd.read_excel('ficheros/TweetsConTopic/tweets_spainGeo_topic.xlsx', header=0, encoding='iso8859_15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Tokenización y stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Lourdes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Se descargan las palabras de parada en español\n",
    "nltk.download(\"stopwords\")\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtenemos los signos de puntuación que se utilizan en español\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se definen las funciones para realizar la tokenización y el stemming\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # Eliminamos lo que no sean palabras\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # Tokenización\n",
    "    tokens = tknzr.tokenize(text)\n",
    "\n",
    "    # Stemming\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_split': 1e-07,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscamos los parámetros que podemos utilizar para entrenar el modelo\n",
    "DecisionTreeClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de', 'la'...it=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'cls__criterion': ('gini', 'entropy'), 'cls__splitter': ('best', 'random'), 'cls__class_weight': ['balanced', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el pipeline para poder encadenar todos los elementos necesarios para realizar la estimación.\n",
    "# Realizamos la búsqueda mediante GridSearhCV, que es una librería de sklearn que permite realizar una\n",
    "# búsqueda de los mejores parámetros del modelo, utulizando los parámetros definidos en parameters y como\n",
    "# métrica, roc_auc (área bajo la curva ROC)\n",
    "pipeline = Pipeline([\n",
    "    ('vect',  CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)),\n",
    "    ('cls', DecisionTreeClassifier())])\n",
    "parameters = {\n",
    "    'cls__criterion': ('gini','entropy'),\n",
    "    'cls__splitter': ('best','random'),\n",
    "    'cls__class_weight':['balanced', None]    \n",
    "}\n",
    "gs = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring='roc_auc')\n",
    "gs.fit(tweets_df.content, tweets_df.polarity_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls__class_weight': None,\n",
       " 'cls__criterion': 'entropy',\n",
       " 'cls__splitter': 'best'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los mejores parámetros del SVC obtenidos de la búsqueda con GridSearchCV \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Los mejores parámetros que encuentra GridSearchCV para el SVC utilizando la métrica roc_auc son:\n",
    "class_weight = None,\n",
    "criterion = 'entropy',\n",
    "splitter = 'best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ResultadosGridSearch/grid_searchDecisionTree.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardamos el resultado del GridSearchCV en un fichero de manera persistente\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gs, 'ficheros/ResultadosGridSearch/grid_searchDecisionTree.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 3. Rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68963005024562252"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mediante validación cruzada obtenemos el rendimiento del modelo\n",
    "model = DecisionTreeClassifier(class_weight = None, criterion = 'entropy', splitter = 'best')\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = spanish_stopwords,\n",
    "    min_df = 0,\n",
    "    max_df = 4700,\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "tweets_df_data_features = vectorizer.fit_transform(tweets_df.content)\n",
    "tweets_df_data_features_nd = tweets_df_data_features.toarray()\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    tweets_df_data_features_nd[0:len(tweets_df)],\n",
    "    y=tweets_df.polarity_bin,\n",
    "    scoring='roc_auc',\n",
    "    cv=None\n",
    "    )\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "El valor que se obtiene del rendimiento del modelo para la métrica de Área bajo la Curva ROC es de 0.68963005024562252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Predicción de la polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Una vez que tenemos el modelo que mejor métrica nos aporta (tras realizar muchas pruebas con distintas métricas \n",
    "# y parámetros pasados al modelo), volvemos a crear un pipeline pero en este caso, pasándole los mejores parámetros\n",
    "# obtenidos del SVC para predecir qué polaridad tienen los tweets que están aún sin etiquetar\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            min_df = 0,\n",
    "            max_df = 26363,\n",
    "            max_features=1000\n",
    "            )),\n",
    "    ('cls', DecisionTreeClassifier(class_weight = None, criterion = 'entropy', splitter = 'best'))\n",
    "])\n",
    "\n",
    "pipeline.fit(tweets_df.content, tweets_df.polarity_bin)\n",
    "tweets['polarity'] = pipeline.predict(tweets.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17229</th>\n",
       "      <td>¡Felicidades una de las de toda la vida! \\n Qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21779</th>\n",
       "      <td>Eres una en un millón, no hay comparación, com...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9578</th>\n",
       "      <td>Mi primo tocando en el cafeberlin @ Café Berlin</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>Fiesta de Primavera CMU MARA  @ Colegio Mayor ...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>Un tribunal mauritano ratifica la pena de muer...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14185</th>\n",
       "      <td>#finalfour es ahora una tendencia en Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>tendencias-twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15362</th>\n",
       "      <td>Hemos sido 3 Diegos, 2 Cristinas, 2 Lunas y 3 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17831</th>\n",
       "      <td>Estoy muy dispuesto a morir derramando mi sang...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>Dicen que los gatos son ariscos y no dan muest...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7458</th>\n",
       "      <td>Conoce nuestro apto Victoria y tendrás el mejo...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25039</th>\n",
       "      <td>\"El Calderón gana partidos\"  \\n\\n...y me ha re...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>La banca admite que la justicia no avala el lí...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20412</th>\n",
       "      <td>A @planea2madrid nos encanta salir a correr lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>La diferencia entre las nuevas tendencias de c...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22308</th>\n",
       "      <td>A por la tercera.\\n#IIIRepublica @ Puerta del ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sitios-madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9388</th>\n",
       "      <td>@BluerpleFTW yo llevo años sin hacerlo xD</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>¿Eres de los que nunca recuerdan un nombre? La...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19116</th>\n",
       "      <td>Florenceeee (@ Palacio Vistalegre Arena in Mad...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>@HablarporHablar ¿Adonde va el dinero de ls im...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>HOY EN  de 17:00 a 18:00 \\nTATUAREMOS EN DIREC...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  polarity  \\\n",
       "17229  ¡Felicidades una de las de toda la vida! \\n Qu...         1   \n",
       "21779  Eres una en un millón, no hay comparación, com...         0   \n",
       "9578    Mi primo tocando en el cafeberlin @ Café Berlin          1   \n",
       "19254  Fiesta de Primavera CMU MARA  @ Colegio Mayor ...         0   \n",
       "4356   Un tribunal mauritano ratifica la pena de muer...         0   \n",
       "14185        #finalfour es ahora una tendencia en Spain          1   \n",
       "15362  Hemos sido 3 Diegos, 2 Cristinas, 2 Lunas y 3 ...         1   \n",
       "17831  Estoy muy dispuesto a morir derramando mi sang...         1   \n",
       "20995  Dicen que los gatos son ariscos y no dan muest...         0   \n",
       "7458   Conoce nuestro apto Victoria y tendrás el mejo...         1   \n",
       "25039  \"El Calderón gana partidos\"  \\n\\n...y me ha re...         1   \n",
       "4056   La banca admite que la justicia no avala el lí...         1   \n",
       "20412  A @planea2madrid nos encanta salir a correr lo...         1   \n",
       "2468   La diferencia entre las nuevas tendencias de c...         1   \n",
       "22308  A por la tercera.\\n#IIIRepublica @ Puerta del ...         0   \n",
       "9388           @BluerpleFTW yo llevo años sin hacerlo xD         0   \n",
       "8444   ¿Eres de los que nunca recuerdan un nombre? La...         0   \n",
       "19116  Florenceeee (@ Palacio Vistalegre Arena in Mad...         1   \n",
       "8311   @HablarporHablar ¿Adonde va el dinero de ls im...         1   \n",
       "11137  HOY EN  de 17:00 a 18:00 \\nTATUAREMOS EN DIREC...         1   \n",
       "\n",
       "                    Topic  \n",
       "17229               otros  \n",
       "21779               otros  \n",
       "9578                otros  \n",
       "19254               otros  \n",
       "4356                otros  \n",
       "14185  tendencias-twitter  \n",
       "15362               otros  \n",
       "17831               otros  \n",
       "20995               otros  \n",
       "7458                otros  \n",
       "25039               otros  \n",
       "4056                otros  \n",
       "20412               otros  \n",
       "2468                otros  \n",
       "22308       sitios-madrid  \n",
       "9388                otros  \n",
       "8444                otros  \n",
       "19116               otros  \n",
       "8311                otros  \n",
       "11137               otros  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos algunos de los tweets que han sido etiquetados con la polaridad\n",
    "tweets[['content', 'polarity','Topic']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en un fichero csv con su polaridad\n",
    "tweets[[ 'content', 'Latitude', 'Longitude', 'polarity','Topic']].to_csv('ficheros/TweetsConPolaridadYTopic/tweetsDecisionTree_polarity_bin.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en fichero excel\n",
    "tweets[['content','Latitude','Longitude','polarity','Topic']].to_excel('ficheros/TweetsConPolaridadYTopicExcel/tweetsDecisionTree_polarity_bin.xlsx', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El notebook está licenciado libremente bajo la licencia [Creative Commons Attribution Share-Alike](https://creativecommons.org/licenses/by/2.0/).\n",
    "\n",
    "La base del código empleado procede del trabajo de Manuel Garrido llamado [Cómo hacer Análisis de Sentimiento en español](http://pybonacci.org/2015/11/24/como-hacer-analisis-de-sentimiento-en-espanol-2/).\n",
    "\n",
    "© 2017 - Juan Bermudo Mera, Margarita Bolívar Jiménez, Lourdes Fernández Nieto, Ramón Pérez Hernández.\n",
    "\n",
    "Universidad Politécnica de Madrid."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
