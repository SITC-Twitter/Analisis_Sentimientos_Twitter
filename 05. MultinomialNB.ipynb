{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/UPM/EscPolitecnica/EscUpmPolit_p.gif \"UPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo final SITC\n",
    "## An√°lisis de sentimientos en Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Departamento de Ingenier√≠a de Sistemas Telem√°ticos. Universidad Polit√©cnica de Madrid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizado por:\n",
    "- Juan Bermudo Mera\n",
    "- Margarita Bol√≠var Jim√©nez\n",
    "- Lourdes Fern√°ndez Nieto\n",
    "- Ram√≥n P√©rez Hern√°ndez\n",
    "\n",
    "¬© 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo MultinomialNB aplicado sobre el fichero de tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "\n",
    "* [Importaci√≥n de datos necesarios para aplicar el algoritmo](#1.-Importaci√≥n-de-datos-necesarios-para-aplicar-el-algoritmo)\n",
    "\t* [Importaci√≥n de librer√≠as](#Importaci√≥n-de-librer√≠as)\n",
    "    * [Importaci√≥n de corpus y tweets](#Importaci√≥n-de-corpus-y-tweets)\n",
    "    * [Tokenizaci√≥n y stemming](#Tokenizaci√≥n-y-stemming)\n",
    "* [Entrenamiento del modelo](#2.-Entrenamiento-del-modelo)\n",
    "* [Rendimiento del modelo](#3.-Rendimiento-del-modelo)\n",
    "* [Predicci√≥n de la polaridad](#4.-Predicci√≥n-de-la-polaridad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de datos necesarios para aplicar el algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lourdes/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Lourdes/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importamos librer√≠as. Las que no est√°n instaladas, instalar con pip install <nombre_paquete>\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Importaci√≥n de corpus y tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se importan el corpus y los tweets\n",
    "tweets_df = pd.read_excel('ficheros/Preprocesados/tweets_corpus_header.xlsx', header=0, encoding='iso8859_15')\n",
    "tweets = pd.read_excel('ficheros/TweetsConTopic/tweets_spainGeo_topic.xlsx', header=0, encoding='iso8859_15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Tokenizaci√≥n y stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Lourdes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Se descargan las palabras de parada en espa√±ol\n",
    "nltk.download(\"stopwords\")\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtenemos los signos de puntuaci√≥n que se utilizan en espa√±ol\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¬ø', '¬°'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se definen las funciones para realizar la tokenizaci√≥n y el stemming\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # Eliminamos lo que no sean palabras\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # Tokenizaci√≥n\n",
    "    tokens = tknzr.tokenize(text)\n",
    "\n",
    "    # Stemming\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscamos los par√°metros que podemos utilizar para entrenar el modelo\n",
    "MultinomialNB().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['de', 'la'...x111b34ea0>, vocabulary=None)), ('cls', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'cls__alpha': (0.001, 0.01, 0.1, 1)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el pipeline para poder encadenar todos los elementos necesarios para realizar la estimaci√≥n.\n",
    "# Realizamos la b√∫squeda mediante GridSearhCV, que es una librer√≠a de sklearn que permite realizar una\n",
    "# b√∫squeda de los mejores par√°metros del modelo, utulizando los par√°metros definidos en parameters y como\n",
    "# m√©trica, roc_auc (√°rea bajo la curva ROC)\n",
    "pipeline = Pipeline([\n",
    "    ('vect',  CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)),\n",
    "    ('cls', MultinomialNB())])\n",
    "parameters = {\n",
    "    'cls__alpha': (0.001, 0.01, 0.1, 1)\n",
    "}\n",
    "gs = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring='roc_auc')\n",
    "gs.fit(tweets_df.content, tweets_df.polarity_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls__alpha': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los mejores par√°metros del SVC obtenidos de la b√∫squeda con GridSearchCV \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El mejor par√°metro que encuentra GridSearchCV para MultinomialNB es de alplha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ResultadosGridSearch/grid_searchMultinomialNB.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardamos el resultado del GridSearchCV en un fichero de manera persistente\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gs, 'ficheros/ResultadosGridSearch/grid_searchMultinomialNB.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 3. Rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85473085654733971"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mediante validaci√≥n cruzada obtenemos el rendimiento del modelo\n",
    "model = MultinomialNB(alpha=1)\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = spanish_stopwords,\n",
    "    min_df = 0,\n",
    "    max_df = 4701,\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "tweets_df_data_features = vectorizer.fit_transform(tweets_df.content)\n",
    "tweets_df_data_features_nd = tweets_df_data_features.toarray()\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    tweets_df_data_features_nd[0:len(tweets_df)],\n",
    "    y=tweets_df.polarity_bin,\n",
    "    scoring='roc_auc',\n",
    "    cv=None\n",
    "    )\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "El valor que se obtiene del rendimiento del modelo para la m√©trica de √Årea bajo la Curva ROC es de 0.85473085654733971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Predicci√≥n de la polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Una vez que tenemos el modelo que mejor m√©trica nos aporta (tras realizar muchas pruebas con distintas m√©tricas \n",
    "# y par√°metros pasados al modelo), volvemos a crear un pipeline pero en este caso, pas√°ndole los mejores par√°metros\n",
    "# obtenidos del SVC para predecir qu√© polaridad tienen los tweets que est√°n a√∫n sin etiquetar\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "            analyzer = 'word',\n",
    "            tokenizer = tokenize,\n",
    "            lowercase = True,\n",
    "            stop_words = spanish_stopwords,\n",
    "            min_df = 0,\n",
    "            max_df = 26363,\n",
    "            max_features=1000\n",
    "            )),\n",
    "    ('cls', MultinomialNB(alpha=1))\n",
    "])\n",
    "\n",
    "pipeline.fit(tweets_df.content, tweets_df.polarity_bin)\n",
    "tweets['polarity'] = pipeline.predict(tweets.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>polarity</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17292</th>\n",
       "      <td>Y es que tenemos aut√©nticos atletas en @carlan...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>Fot√≥n! Viva Florence!!!! @ Palacio Vistalegre</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>Vaya trio de artistas. Los pelos de punta. @ V...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>Alguien me da conversaci√≥n ? ü§î</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25359</th>\n",
       "      <td>S√≠ pod√©is ayudar est√° noche a las 21:00, para ...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>Sin filtros, sin m√°s. #hdr #lgg3 #isabellacato...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>Creo que ya he pillado el truco a Debod @ Madr...</td>\n",
       "      <td>0</td>\n",
       "      <td>sitios-madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>@patricio_kira por sus contenidos en Twitter, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22145</th>\n",
       "      <td>#ItsARainingDay #Flowers #Flores #PrimaveraEJD...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25531</th>\n",
       "      <td>#Egaylity -  Ringo Starr cancel√≥ concierto por...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23775</th>\n",
       "      <td>(Primas) hermanas &amp;lt;3 @ Madrid-Espa√±a</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>@Liber_Alles me encanta el concierto para dos ...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>¬øEstudias Ingenier√≠a Electr√≥nica o El√©ctrica? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>\"No temo al enemigo que me ataca, si no al fal...</td>\n",
       "      <td>1</td>\n",
       "      <td>sitios-madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18228</th>\n",
       "      <td>No soy adicta a nada,todo en su justa medida,p...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21935</th>\n",
       "      <td>I'm at Pabell√≥n de Cristal in Madrid</td>\n",
       "      <td>1</td>\n",
       "      <td>sitios-madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>ayer eramos rookies hoy somos all-stars @ Parq...</td>\n",
       "      <td>1</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14240</th>\n",
       "      <td>Porq el se√±or tu Dios  estara contigo vivamos ...</td>\n",
       "      <td>0</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>puntuarme f√≠sico y personalidad  ‚Äî Tu en todo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25017</th>\n",
       "      <td>Reconociendo las fronteras, los limites de cad...</td>\n",
       "      <td>1</td>\n",
       "      <td>otros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  polarity  \\\n",
       "17292  Y es que tenemos aut√©nticos atletas en @carlan...         1   \n",
       "18898     Fot√≥n! Viva Florence!!!! @ Palacio Vistalegre          1   \n",
       "21449  Vaya trio de artistas. Los pelos de punta. @ V...         0   \n",
       "8961                      Alguien me da conversaci√≥n ? ü§î         0   \n",
       "25359  S√≠ pod√©is ayudar est√° noche a las 21:00, para ...         1   \n",
       "10266  Sin filtros, sin m√°s. #hdr #lgg3 #isabellacato...         1   \n",
       "12279  Creo que ya he pillado el truco a Debod @ Madr...         0   \n",
       "2801   @patricio_kira por sus contenidos en Twitter, ...         1   \n",
       "22145  #ItsARainingDay #Flowers #Flores #PrimaveraEJD...         1   \n",
       "25531  #Egaylity -  Ringo Starr cancel√≥ concierto por...         0   \n",
       "23775           (Primas) hermanas &lt;3 @ Madrid-Espa√±a          1   \n",
       "4040   @Liber_Alles me encanta el concierto para dos ...         1   \n",
       "5044   ¬øEstudias Ingenier√≠a Electr√≥nica o El√©ctrica? ...         0   \n",
       "14520  \"No temo al enemigo que me ataca, si no al fal...         1   \n",
       "18228  No soy adicta a nada,todo en su justa medida,p...         1   \n",
       "21935              I'm at Pabell√≥n de Cristal in Madrid          1   \n",
       "10039  ayer eramos rookies hoy somos all-stars @ Parq...         1   \n",
       "14240  Porq el se√±or tu Dios  estara contigo vivamos ...         0   \n",
       "7606   puntuarme f√≠sico y personalidad  ‚Äî Tu en todo ...         1   \n",
       "25017  Reconociendo las fronteras, los limites de cad...         1   \n",
       "\n",
       "               Topic  \n",
       "17292          otros  \n",
       "18898          otros  \n",
       "21449          otros  \n",
       "8961           otros  \n",
       "25359          otros  \n",
       "10266          otros  \n",
       "12279  sitios-madrid  \n",
       "2801           otros  \n",
       "22145          otros  \n",
       "25531          otros  \n",
       "23775          otros  \n",
       "4040           otros  \n",
       "5044           otros  \n",
       "14520  sitios-madrid  \n",
       "18228          otros  \n",
       "21935  sitios-madrid  \n",
       "10039         retiro  \n",
       "14240          otros  \n",
       "7606           otros  \n",
       "25017          otros  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos algunos de los tweets que han sido etiquetados con la polaridad\n",
    "tweets[['content', 'polarity','Topic']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en un fichero csv con su polaridad\n",
    "tweets[[ 'content', 'Latitude', 'Longitude', 'polarity','Topic']].to_csv('ficheros/TweetsConPolaridadYTopic/tweetsMultinomialNB_polarity_bin.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardamos los tweets en fichero excel\n",
    "tweets[['content','Latitude','Longitude','polarity','Topic']].to_excel('ficheros/TweetsConPolaridadYTopicExcel/tweetsMultinomialNB_polarity_bin.xlsx', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El notebook est√° licenciado libremente bajo la licencia [Creative Commons Attribution Share-Alike](https://creativecommons.org/licenses/by/2.0/).\n",
    "\n",
    "La base del c√≥digo empleado procede del trabajo de Manuel Garrido llamado [C√≥mo hacer An√°lisis de Sentimiento en espa√±ol](http://pybonacci.org/2015/11/24/como-hacer-analisis-de-sentimiento-en-espanol-2/).\n",
    "\n",
    "¬© 2017 - Juan Bermudo Mera, Margarita Bol√≠var Jim√©nez, Lourdes Fern√°ndez Nieto, Ram√≥n P√©rez Hern√°ndez.\n",
    "\n",
    "Universidad Polit√©cnica de Madrid."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
